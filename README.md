### Data Engineering Project(s)

The purpose of this repository is to give Data Engineers the chance to
complete an end-to-end Data Engineering project from start to finish. Complete
instructions will be given on the desired architecture and steps to 
take to complete each project.

The expectation of these Project(s) is that you will do everything, including Bash, Dockerfiles, README's, coding, etc.
Nothing is going to be done for you, it forces you to not rely on others and skip
things you might not be familiar with. Growth comes with struggle.

Similar to how work for a project might be handed down in a
Data Team, some of the instructions will be specific, some will be
ambiguous, and the solution you choose will be generally up to you.

This project(s) will test a Data Engineers abilities across
multiple techs and concepts not limited to, but including

- `Docker`
- `Bash`
- `Python`
- `Airflow`
- `Async`
- `Data Modeling`
- `Postgres`
- `Delta Lake`
- `PySpark`
- `Parquet/CSV`
- `BytesIO`
- `Lazy Evaluation`
- `SQL`
- `Analytics`
- `Dashboards`
- `AWS Cloud`

Good Data Engineers are well-rounded and are able to work across multiple techs and concepts,
as well as the ability to understand clear and unclear directions, and develop architecture to support
the requirements.
